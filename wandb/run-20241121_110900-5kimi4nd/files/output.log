  0%|                                                                          | 0/1890 [00:00<?, ?it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  5%|███▍                                                            | 100/1890 [01:03<15:07,  1.97it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.6928, 'grad_norm': 106443.921875, 'learning_rate': 4.973544973544973e-05, 'epoch': 0.05}
{'loss': 0.6881, 'grad_norm': 132966.5, 'learning_rate': 4.9470899470899475e-05, 'epoch': 0.11}
{'loss': 0.6688, 'grad_norm': 332009.78125, 'learning_rate': 4.9206349206349204e-05, 'epoch': 0.16}
{'loss': 0.6229, 'grad_norm': 332439.09375, 'learning_rate': 4.894179894179895e-05, 'epoch': 0.21}
{'loss': 0.6051, 'grad_norm': 342799.09375, 'learning_rate': 4.8677248677248676e-05, 'epoch': 0.26}
{'loss': 0.6414, 'grad_norm': 323605.34375, 'learning_rate': 4.841269841269841e-05, 'epoch': 0.32}
{'loss': 0.6078, 'grad_norm': 354294.65625, 'learning_rate': 4.814814814814815e-05, 'epoch': 0.37}
{'loss': 0.627, 'grad_norm': 173623.140625, 'learning_rate': 4.7883597883597884e-05, 'epoch': 0.42}
{'loss': 0.5671, 'grad_norm': 367514.875, 'learning_rate': 4.761904761904762e-05, 'epoch': 0.48}
{'loss': 0.649, 'grad_norm': 127089.8828125, 'learning_rate': 4.7354497354497356e-05, 'epoch': 0.53}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.5818451642990112, 'eval_accuracy': 0.7085127525670752, 'eval_runtime': 8.7376, 'eval_samples_per_second': 345.518, 'eval_steps_per_second': 5.493, 'epoch': 0.53}
 11%|██████▊                                                         | 200/1890 [02:02<14:21,  1.96it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.6047, 'grad_norm': 973168.3125, 'learning_rate': 4.708994708994709e-05, 'epoch': 0.58}
{'loss': 0.5905, 'grad_norm': 494390.65625, 'learning_rate': 4.682539682539683e-05, 'epoch': 0.63}
{'loss': 0.5536, 'grad_norm': 221361.40625, 'learning_rate': 4.656084656084656e-05, 'epoch': 0.69}
{'loss': 0.6138, 'grad_norm': 242946.0, 'learning_rate': 4.62962962962963e-05, 'epoch': 0.74}
{'loss': 0.5972, 'grad_norm': 153034.171875, 'learning_rate': 4.603174603174603e-05, 'epoch': 0.79}
{'loss': 0.5499, 'grad_norm': 302731.3125, 'learning_rate': 4.576719576719577e-05, 'epoch': 0.85}
{'loss': 0.5754, 'grad_norm': 295687.09375, 'learning_rate': 4.55026455026455e-05, 'epoch': 0.9}
{'loss': 0.5631, 'grad_norm': 535483.8125, 'learning_rate': 4.523809523809524e-05, 'epoch': 0.95}
{'loss': 0.5578, 'grad_norm': 285129.25, 'learning_rate': 4.4973544973544974e-05, 'epoch': 1.01}
{'loss': 0.5088, 'grad_norm': 303803.0, 'learning_rate': 4.470899470899471e-05, 'epoch': 1.06}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.5499516129493713, 'eval_accuracy': 0.7121563431599868, 'eval_runtime': 8.8988, 'eval_samples_per_second': 339.261, 'eval_steps_per_second': 5.394, 'epoch': 1.06}
 16%|██████████▏                                                     | 300/1890 [03:00<13:00,  2.04it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.5064, 'grad_norm': 377061.4375, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.11}
{'loss': 0.4968, 'grad_norm': 293965.0, 'learning_rate': 4.417989417989418e-05, 'epoch': 1.16}
{'loss': 0.4997, 'grad_norm': 320031.125, 'learning_rate': 4.391534391534391e-05, 'epoch': 1.22}
{'loss': 0.5427, 'grad_norm': 667681.9375, 'learning_rate': 4.3650793650793655e-05, 'epoch': 1.27}
{'loss': 0.4825, 'grad_norm': 310692.09375, 'learning_rate': 4.3386243386243384e-05, 'epoch': 1.32}
{'loss': 0.5326, 'grad_norm': 261698.234375, 'learning_rate': 4.312169312169313e-05, 'epoch': 1.38}
{'loss': 0.497, 'grad_norm': 286939.0625, 'learning_rate': 4.2857142857142856e-05, 'epoch': 1.43}
{'loss': 0.5193, 'grad_norm': 303830.96875, 'learning_rate': 4.259259259259259e-05, 'epoch': 1.48}
{'loss': 0.484, 'grad_norm': 263227.03125, 'learning_rate': 4.232804232804233e-05, 'epoch': 1.53}
{'loss': 0.5664, 'grad_norm': 284002.75, 'learning_rate': 4.2063492063492065e-05, 'epoch': 1.59}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.5470690131187439, 'eval_accuracy': 0.7161311692613448, 'eval_runtime': 8.7959, 'eval_samples_per_second': 343.229, 'eval_steps_per_second': 5.457, 'epoch': 1.59}
 21%|█████████████▌                                                  | 400/1890 [03:59<12:20,  2.01it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.4959, 'grad_norm': 261365.265625, 'learning_rate': 4.17989417989418e-05, 'epoch': 1.64}
{'loss': 0.5106, 'grad_norm': 398599.96875, 'learning_rate': 4.153439153439154e-05, 'epoch': 1.69}
{'loss': 0.5003, 'grad_norm': 385416.0, 'learning_rate': 4.126984126984127e-05, 'epoch': 1.75}
{'loss': 0.5169, 'grad_norm': 325785.875, 'learning_rate': 4.100529100529101e-05, 'epoch': 1.8}
{'loss': 0.463, 'grad_norm': 295525.28125, 'learning_rate': 4.074074074074074e-05, 'epoch': 1.85}
{'loss': 0.5011, 'grad_norm': 339844.0625, 'learning_rate': 4.047619047619048e-05, 'epoch': 1.9}
{'loss': 0.5013, 'grad_norm': 333973.375, 'learning_rate': 4.021164021164021e-05, 'epoch': 1.96}
{'loss': 0.4638, 'grad_norm': 309668.0625, 'learning_rate': 3.9947089947089946e-05, 'epoch': 2.01}
{'loss': 0.4067, 'grad_norm': 393975.0625, 'learning_rate': 3.968253968253968e-05, 'epoch': 2.06}
{'loss': 0.3983, 'grad_norm': 492919.90625, 'learning_rate': 3.941798941798942e-05, 'epoch': 2.12}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.6483045816421509, 'eval_accuracy': 0.7105001656177542, 'eval_runtime': 8.7653, 'eval_samples_per_second': 344.427, 'eval_steps_per_second': 5.476, 'epoch': 2.12}
 26%|████████████████▉                                               | 500/1890 [05:17<17:35,  1.32it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.3546, 'grad_norm': 496275.375, 'learning_rate': 3.9153439153439155e-05, 'epoch': 2.17}
{'loss': 0.3578, 'grad_norm': 468424.0, 'learning_rate': 3.888888888888889e-05, 'epoch': 2.22}
{'loss': 0.387, 'grad_norm': 530807.75, 'learning_rate': 3.862433862433863e-05, 'epoch': 2.28}
{'loss': 0.3945, 'grad_norm': 516284.28125, 'learning_rate': 3.835978835978836e-05, 'epoch': 2.33}
{'loss': 0.371, 'grad_norm': 578278.6875, 'learning_rate': 3.809523809523809e-05, 'epoch': 2.38}
{'loss': 0.4403, 'grad_norm': 557078.5, 'learning_rate': 3.7830687830687835e-05, 'epoch': 2.43}
{'loss': 0.3895, 'grad_norm': 420392.34375, 'learning_rate': 3.7566137566137564e-05, 'epoch': 2.49}
{'loss': 0.4076, 'grad_norm': 395658.53125, 'learning_rate': 3.730158730158731e-05, 'epoch': 2.54}
{'loss': 0.372, 'grad_norm': 468262.46875, 'learning_rate': 3.7037037037037037e-05, 'epoch': 2.59}
{'loss': 0.4323, 'grad_norm': 325345.21875, 'learning_rate': 3.677248677248677e-05, 'epoch': 2.65}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.6399710774421692, 'eval_accuracy': 0.7121563431599868, 'eval_runtime': 12.9155, 'eval_samples_per_second': 233.751, 'eval_steps_per_second': 3.716, 'epoch': 2.65}
 32%|████████████████████▎                                           | 600/1890 [06:46<15:52,  1.36it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.403, 'grad_norm': 477707.15625, 'learning_rate': 3.650793650793651e-05, 'epoch': 2.7}
{'loss': 0.4072, 'grad_norm': 509637.40625, 'learning_rate': 3.6243386243386245e-05, 'epoch': 2.75}
{'loss': 0.4291, 'grad_norm': 341277.5625, 'learning_rate': 3.597883597883598e-05, 'epoch': 2.8}
{'loss': 0.4208, 'grad_norm': 428191.65625, 'learning_rate': 3.571428571428572e-05, 'epoch': 2.86}
{'loss': 0.395, 'grad_norm': 591275.9375, 'learning_rate': 3.5449735449735446e-05, 'epoch': 2.91}
{'loss': 0.4065, 'grad_norm': 448979.625, 'learning_rate': 3.518518518518519e-05, 'epoch': 2.96}
{'loss': 0.3981, 'grad_norm': 494436.90625, 'learning_rate': 3.492063492063492e-05, 'epoch': 3.02}
{'loss': 0.3055, 'grad_norm': 711840.9375, 'learning_rate': 3.465608465608466e-05, 'epoch': 3.07}
{'loss': 0.2551, 'grad_norm': 630265.9375, 'learning_rate': 3.439153439153439e-05, 'epoch': 3.12}
{'loss': 0.2994, 'grad_norm': 642821.5625, 'learning_rate': 3.412698412698413e-05, 'epoch': 3.17}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.7371306419372559, 'eval_accuracy': 0.7161311692613448, 'eval_runtime': 12.9704, 'eval_samples_per_second': 232.761, 'eval_steps_per_second': 3.701, 'epoch': 3.17}
 37%|███████████████████████▋                                        | 700/1890 [08:13<14:51,  1.34it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.2581, 'grad_norm': 419727.0625, 'learning_rate': 3.386243386243386e-05, 'epoch': 3.23}
{'loss': 0.3279, 'grad_norm': 1448425.5, 'learning_rate': 3.35978835978836e-05, 'epoch': 3.28}
{'loss': 0.2485, 'grad_norm': 309384.625, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.33}
{'loss': 0.2871, 'grad_norm': 635387.0625, 'learning_rate': 3.306878306878307e-05, 'epoch': 3.39}
{'loss': 0.2829, 'grad_norm': 694411.4375, 'learning_rate': 3.280423280423281e-05, 'epoch': 3.44}
{'loss': 0.3787, 'grad_norm': 727707.375, 'learning_rate': 3.253968253968254e-05, 'epoch': 3.49}
{'loss': 0.2987, 'grad_norm': 551031.75, 'learning_rate': 3.227513227513227e-05, 'epoch': 3.54}
{'loss': 0.2506, 'grad_norm': 799746.3125, 'learning_rate': 3.2010582010582015e-05, 'epoch': 3.6}
{'loss': 0.2983, 'grad_norm': 403045.28125, 'learning_rate': 3.1746031746031745e-05, 'epoch': 3.65}
{'loss': 0.3096, 'grad_norm': 538946.5, 'learning_rate': 3.148148148148148e-05, 'epoch': 3.7}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.7124139070510864, 'eval_accuracy': 0.7091752235839682, 'eval_runtime': 12.9372, 'eval_samples_per_second': 233.358, 'eval_steps_per_second': 3.71, 'epoch': 3.7}
 42%|███████████████████████████                                     | 800/1890 [09:39<13:17,  1.37it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.2547, 'grad_norm': 485345.21875, 'learning_rate': 3.121693121693122e-05, 'epoch': 3.76}
{'loss': 0.2733, 'grad_norm': 1203429.25, 'learning_rate': 3.095238095238095e-05, 'epoch': 3.81}
{'loss': 0.309, 'grad_norm': 782577.75, 'learning_rate': 3.068783068783069e-05, 'epoch': 3.86}
{'loss': 0.3152, 'grad_norm': 496488.75, 'learning_rate': 3.0423280423280425e-05, 'epoch': 3.92}
{'loss': 0.2916, 'grad_norm': 662860.4375, 'learning_rate': 3.0158730158730158e-05, 'epoch': 3.97}
{'loss': 0.247, 'grad_norm': 648148.875, 'learning_rate': 2.9894179894179897e-05, 'epoch': 4.02}
{'loss': 0.1427, 'grad_norm': 1168701.375, 'learning_rate': 2.962962962962963e-05, 'epoch': 4.07}
{'loss': 0.2262, 'grad_norm': 1510084.0, 'learning_rate': 2.9365079365079366e-05, 'epoch': 4.13}
{'loss': 0.1597, 'grad_norm': 877959.5, 'learning_rate': 2.91005291005291e-05, 'epoch': 4.18}
{'loss': 0.1828, 'grad_norm': 1095295.5, 'learning_rate': 2.8835978835978838e-05, 'epoch': 4.23}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.9698084592819214, 'eval_accuracy': 0.699900629347466, 'eval_runtime': 12.9014, 'eval_samples_per_second': 234.006, 'eval_steps_per_second': 3.721, 'epoch': 4.23}
 48%|██████████████████████████████▍                                 | 900/1890 [11:06<12:13,  1.35it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.2124, 'grad_norm': 691796.25, 'learning_rate': 2.857142857142857e-05, 'epoch': 4.29}
{'loss': 0.2071, 'grad_norm': 697942.0, 'learning_rate': 2.830687830687831e-05, 'epoch': 4.34}
{'loss': 0.1749, 'grad_norm': 514478.125, 'learning_rate': 2.8042328042328043e-05, 'epoch': 4.39}
{'loss': 0.1672, 'grad_norm': 623333.8125, 'learning_rate': 2.777777777777778e-05, 'epoch': 4.44}
{'loss': 0.1759, 'grad_norm': 326933.1875, 'learning_rate': 2.7513227513227512e-05, 'epoch': 4.5}
{'loss': 0.1795, 'grad_norm': 516034.4375, 'learning_rate': 2.724867724867725e-05, 'epoch': 4.55}
{'loss': 0.1826, 'grad_norm': 608840.3125, 'learning_rate': 2.6984126984126984e-05, 'epoch': 4.6}
{'loss': 0.2265, 'grad_norm': 1070096.625, 'learning_rate': 2.6719576719576723e-05, 'epoch': 4.66}
{'loss': 0.1689, 'grad_norm': 654984.75, 'learning_rate': 2.6455026455026456e-05, 'epoch': 4.71}
{'loss': 0.1831, 'grad_norm': 795511.4375, 'learning_rate': 2.6190476190476192e-05, 'epoch': 4.76}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 0.996085524559021, 'eval_accuracy': 0.6816826763829082, 'eval_runtime': 12.9572, 'eval_samples_per_second': 232.997, 'eval_steps_per_second': 3.704, 'epoch': 4.76}
 53%|█████████████████████████████████▎                             | 1000/1890 [12:33<11:14,  1.32it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.2008, 'grad_norm': 860372.375, 'learning_rate': 2.5925925925925925e-05, 'epoch': 4.81}
{'loss': 0.1782, 'grad_norm': 775792.4375, 'learning_rate': 2.5661375661375664e-05, 'epoch': 4.87}
{'loss': 0.2027, 'grad_norm': 671213.875, 'learning_rate': 2.5396825396825397e-05, 'epoch': 4.92}
{'loss': 0.2141, 'grad_norm': 942551.625, 'learning_rate': 2.5132275132275137e-05, 'epoch': 4.97}
{'loss': 0.1984, 'grad_norm': 1038874.3125, 'learning_rate': 2.4867724867724866e-05, 'epoch': 5.03}
{'loss': 0.1186, 'grad_norm': 488053.90625, 'learning_rate': 2.4603174603174602e-05, 'epoch': 5.08}
{'loss': 0.0927, 'grad_norm': 594325.1875, 'learning_rate': 2.4338624338624338e-05, 'epoch': 5.13}
{'loss': 0.1294, 'grad_norm': 1846868.0, 'learning_rate': 2.4074074074074074e-05, 'epoch': 5.19}
{'loss': 0.1631, 'grad_norm': 913220.6875, 'learning_rate': 2.380952380952381e-05, 'epoch': 5.24}
{'loss': 0.0801, 'grad_norm': 368484.03125, 'learning_rate': 2.3544973544973546e-05, 'epoch': 5.29}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.1030217409133911, 'eval_accuracy': 0.699900629347466, 'eval_runtime': 12.7672, 'eval_samples_per_second': 236.466, 'eval_steps_per_second': 3.76, 'epoch': 5.29}
 58%|████████████████████████████████████▋                          | 1100/1890 [14:03<09:51,  1.34it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.1366, 'grad_norm': 1203687.0, 'learning_rate': 2.328042328042328e-05, 'epoch': 5.34}
{'loss': 0.1206, 'grad_norm': 498948.46875, 'learning_rate': 2.3015873015873015e-05, 'epoch': 5.4}
{'loss': 0.1042, 'grad_norm': 1203416.375, 'learning_rate': 2.275132275132275e-05, 'epoch': 5.45}
{'loss': 0.1557, 'grad_norm': 1203012.5, 'learning_rate': 2.2486772486772487e-05, 'epoch': 5.5}
{'loss': 0.1511, 'grad_norm': 1255379.5, 'learning_rate': 2.2222222222222223e-05, 'epoch': 5.56}
{'loss': 0.1394, 'grad_norm': 471448.75, 'learning_rate': 2.1957671957671956e-05, 'epoch': 5.61}
{'loss': 0.1258, 'grad_norm': 604715.5625, 'learning_rate': 2.1693121693121692e-05, 'epoch': 5.66}
{'loss': 0.1332, 'grad_norm': 436262.96875, 'learning_rate': 2.1428571428571428e-05, 'epoch': 5.71}
{'loss': 0.1426, 'grad_norm': 1068531.125, 'learning_rate': 2.1164021164021164e-05, 'epoch': 5.77}
{'loss': 0.1354, 'grad_norm': 906378.25, 'learning_rate': 2.08994708994709e-05, 'epoch': 5.82}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.2124731540679932, 'eval_accuracy': 0.6906260351109639, 'eval_runtime': 12.9756, 'eval_samples_per_second': 232.667, 'eval_steps_per_second': 3.699, 'epoch': 5.82}
 63%|████████████████████████████████████████                       | 1200/1890 [15:25<07:40,  1.50it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.1025, 'grad_norm': 134683.09375, 'learning_rate': 2.0634920634920636e-05, 'epoch': 5.87}
{'loss': 0.1503, 'grad_norm': 727943.9375, 'learning_rate': 2.037037037037037e-05, 'epoch': 5.93}
{'loss': 0.1624, 'grad_norm': 1061515.125, 'learning_rate': 2.0105820105820105e-05, 'epoch': 5.98}
{'loss': 0.1079, 'grad_norm': 780720.1875, 'learning_rate': 1.984126984126984e-05, 'epoch': 6.03}
{'loss': 0.1191, 'grad_norm': 892349.3125, 'learning_rate': 1.9576719576719577e-05, 'epoch': 6.08}
{'loss': 0.0923, 'grad_norm': 470234.9375, 'learning_rate': 1.9312169312169313e-05, 'epoch': 6.14}
{'loss': 0.0808, 'grad_norm': 122661.0703125, 'learning_rate': 1.9047619047619046e-05, 'epoch': 6.19}
{'loss': 0.0589, 'grad_norm': 872848.125, 'learning_rate': 1.8783068783068782e-05, 'epoch': 6.24}
{'loss': 0.116, 'grad_norm': 1583359.5, 'learning_rate': 1.8518518518518518e-05, 'epoch': 6.3}
{'loss': 0.0797, 'grad_norm': 1066902.75, 'learning_rate': 1.8253968253968254e-05, 'epoch': 6.35}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.4080049991607666, 'eval_accuracy': 0.6936071546869824, 'eval_runtime': 11.4006, 'eval_samples_per_second': 264.811, 'eval_steps_per_second': 4.21, 'epoch': 6.35}
 69%|███████████████████████████████████████████▎                   | 1300/1890 [16:44<06:28,  1.52it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.0635, 'grad_norm': 1004948.875, 'learning_rate': 1.798941798941799e-05, 'epoch': 6.4}
{'loss': 0.0934, 'grad_norm': 1992594.625, 'learning_rate': 1.7724867724867723e-05, 'epoch': 6.46}
{'loss': 0.1292, 'grad_norm': 685587.1875, 'learning_rate': 1.746031746031746e-05, 'epoch': 6.51}
{'loss': 0.0534, 'grad_norm': 841844.75, 'learning_rate': 1.7195767195767195e-05, 'epoch': 6.56}
{'loss': 0.1014, 'grad_norm': 336603.03125, 'learning_rate': 1.693121693121693e-05, 'epoch': 6.61}
{'loss': 0.0929, 'grad_norm': 1261311.625, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.67}
{'loss': 0.1212, 'grad_norm': 1059265.0, 'learning_rate': 1.6402116402116404e-05, 'epoch': 6.72}
{'loss': 0.0967, 'grad_norm': 81231.453125, 'learning_rate': 1.6137566137566136e-05, 'epoch': 6.77}
{'loss': 0.0694, 'grad_norm': 288021.1875, 'learning_rate': 1.5873015873015872e-05, 'epoch': 6.83}
{'loss': 0.0807, 'grad_norm': 566216.1875, 'learning_rate': 1.560846560846561e-05, 'epoch': 6.88}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.2691022157669067, 'eval_accuracy': 0.699238158330573, 'eval_runtime': 11.5384, 'eval_samples_per_second': 261.648, 'eval_steps_per_second': 4.16, 'epoch': 6.88}
 74%|██████████████████████████████████████████████▋                | 1400/1890 [18:08<05:50,  1.40it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.1139, 'grad_norm': 310239.5, 'learning_rate': 1.5343915343915344e-05, 'epoch': 6.93}
{'loss': 0.0961, 'grad_norm': 865301.625, 'learning_rate': 1.5079365079365079e-05, 'epoch': 6.98}
{'loss': 0.0593, 'grad_norm': 313359.4375, 'learning_rate': 1.4814814814814815e-05, 'epoch': 7.04}
{'loss': 0.0608, 'grad_norm': 235284.1875, 'learning_rate': 1.455026455026455e-05, 'epoch': 7.09}
{'loss': 0.0506, 'grad_norm': 1979846.375, 'learning_rate': 1.4285714285714285e-05, 'epoch': 7.14}
{'loss': 0.0663, 'grad_norm': 470251.96875, 'learning_rate': 1.4021164021164022e-05, 'epoch': 7.2}
{'loss': 0.0914, 'grad_norm': 778681.0625, 'learning_rate': 1.3756613756613756e-05, 'epoch': 7.25}
{'loss': 0.0829, 'grad_norm': 994492.6875, 'learning_rate': 1.3492063492063492e-05, 'epoch': 7.3}
{'loss': 0.0549, 'grad_norm': 614567.4375, 'learning_rate': 1.3227513227513228e-05, 'epoch': 7.35}
{'loss': 0.0541, 'grad_norm': 182966.890625, 'learning_rate': 1.2962962962962962e-05, 'epoch': 7.41}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.527573585510254, 'eval_accuracy': 0.6975819807883405, 'eval_runtime': 12.3047, 'eval_samples_per_second': 245.353, 'eval_steps_per_second': 3.901, 'epoch': 7.41}
 79%|██████████████████████████████████████████████████             | 1500/1890 [19:28<04:21,  1.49it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.0607, 'grad_norm': 283267.9375, 'learning_rate': 1.2698412698412699e-05, 'epoch': 7.46}
{'loss': 0.0882, 'grad_norm': 549415.5, 'learning_rate': 1.2433862433862433e-05, 'epoch': 7.51}
{'loss': 0.054, 'grad_norm': 93969.9296875, 'learning_rate': 1.2169312169312169e-05, 'epoch': 7.57}
{'loss': 0.0651, 'grad_norm': 723525.0, 'learning_rate': 1.1904761904761905e-05, 'epoch': 7.62}
{'loss': 0.0831, 'grad_norm': 189861.5, 'learning_rate': 1.164021164021164e-05, 'epoch': 7.67}
{'loss': 0.0592, 'grad_norm': 926585.4375, 'learning_rate': 1.1375661375661376e-05, 'epoch': 7.72}
{'loss': 0.0499, 'grad_norm': 974152.0, 'learning_rate': 1.1111111111111112e-05, 'epoch': 7.78}
{'loss': 0.1166, 'grad_norm': 1552957.875, 'learning_rate': 1.0846560846560846e-05, 'epoch': 7.83}
{'loss': 0.0791, 'grad_norm': 1709469.0, 'learning_rate': 1.0582010582010582e-05, 'epoch': 7.88}
{'loss': 0.0656, 'grad_norm': 402804.15625, 'learning_rate': 1.0317460317460318e-05, 'epoch': 7.94}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.5445306301116943, 'eval_accuracy': 0.696588274263001, 'eval_runtime': 11.4287, 'eval_samples_per_second': 264.159, 'eval_steps_per_second': 4.2, 'epoch': 7.94}
 85%|█████████████████████████████████████████████████████▎         | 1600/1890 [20:48<03:11,  1.52it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.063, 'grad_norm': 912802.1875, 'learning_rate': 1.0052910052910053e-05, 'epoch': 7.99}
{'loss': 0.0611, 'grad_norm': 493282.75, 'learning_rate': 9.788359788359789e-06, 'epoch': 8.04}
{'loss': 0.0378, 'grad_norm': 800984.1875, 'learning_rate': 9.523809523809523e-06, 'epoch': 8.1}
{'loss': 0.0632, 'grad_norm': 1473011.5, 'learning_rate': 9.259259259259259e-06, 'epoch': 8.15}
{'loss': 0.0294, 'grad_norm': 553831.375, 'learning_rate': 8.994708994708995e-06, 'epoch': 8.2}
{'loss': 0.049, 'grad_norm': 1241250.0, 'learning_rate': 8.73015873015873e-06, 'epoch': 8.25}
{'loss': 0.0426, 'grad_norm': 850418.125, 'learning_rate': 8.465608465608466e-06, 'epoch': 8.31}
{'loss': 0.0359, 'grad_norm': 87409.40625, 'learning_rate': 8.201058201058202e-06, 'epoch': 8.36}
{'loss': 0.0839, 'grad_norm': 704353.9375, 'learning_rate': 7.936507936507936e-06, 'epoch': 8.41}
{'loss': 0.0939, 'grad_norm': 743622.6875, 'learning_rate': 7.671957671957672e-06, 'epoch': 8.47}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.6458251476287842, 'eval_accuracy': 0.6846637959589268, 'eval_runtime': 11.6539, 'eval_samples_per_second': 259.055, 'eval_steps_per_second': 4.119, 'epoch': 8.47}
 90%|████████████████████████████████████████████████████████▋      | 1700/1890 [22:06<02:11,  1.44it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.049, 'grad_norm': 283267.59375, 'learning_rate': 7.4074074074074075e-06, 'epoch': 8.52}
{'loss': 0.0769, 'grad_norm': 565556.75, 'learning_rate': 7.142857142857143e-06, 'epoch': 8.57}
{'loss': 0.0247, 'grad_norm': 909701.625, 'learning_rate': 6.878306878306878e-06, 'epoch': 8.62}
{'loss': 0.0509, 'grad_norm': 161529.140625, 'learning_rate': 6.613756613756614e-06, 'epoch': 8.68}
{'loss': 0.0633, 'grad_norm': 13807.2001953125, 'learning_rate': 6.349206349206349e-06, 'epoch': 8.73}
{'loss': 0.0401, 'grad_norm': 59639.2421875, 'learning_rate': 6.0846560846560845e-06, 'epoch': 8.78}
{'loss': 0.0708, 'grad_norm': 859012.3125, 'learning_rate': 5.82010582010582e-06, 'epoch': 8.84}
{'loss': 0.0201, 'grad_norm': 680523.375, 'learning_rate': 5.555555555555556e-06, 'epoch': 8.89}
{'loss': 0.0409, 'grad_norm': 2070062.125, 'learning_rate': 5.291005291005291e-06, 'epoch': 8.94}
{'loss': 0.0749, 'grad_norm': 1509932.125, 'learning_rate': 5.026455026455026e-06, 'epoch': 8.99}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.7610318660736084, 'eval_accuracy': 0.7065253395163962, 'eval_runtime': 11.464, 'eval_samples_per_second': 263.346, 'eval_steps_per_second': 4.187, 'epoch': 8.99}
 95%|████████████████████████████████████████████████████████████   | 1800/1890 [23:24<00:59,  1.51it/s]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
{'loss': 0.0327, 'grad_norm': 563249.1875, 'learning_rate': 4.7619047619047615e-06, 'epoch': 9.05}
{'loss': 0.0378, 'grad_norm': 68534.015625, 'learning_rate': 4.497354497354498e-06, 'epoch': 9.1}
{'loss': 0.0167, 'grad_norm': 765353.375, 'learning_rate': 4.232804232804233e-06, 'epoch': 9.15}
{'loss': 0.0372, 'grad_norm': 544181.5625, 'learning_rate': 3.968253968253968e-06, 'epoch': 9.21}
{'loss': 0.0214, 'grad_norm': 247772.3125, 'learning_rate': 3.7037037037037037e-06, 'epoch': 9.26}
{'loss': 0.0719, 'grad_norm': 16988.876953125, 'learning_rate': 3.439153439153439e-06, 'epoch': 9.31}
{'loss': 0.0543, 'grad_norm': 931036.625, 'learning_rate': 3.1746031746031746e-06, 'epoch': 9.37}
{'loss': 0.0656, 'grad_norm': 1526541.5, 'learning_rate': 2.91005291005291e-06, 'epoch': 9.42}
{'loss': 0.061, 'grad_norm': 349287.21875, 'learning_rate': 2.6455026455026455e-06, 'epoch': 9.47}
{'loss': 0.0377, 'grad_norm': 4091.572021484375, 'learning_rate': 2.3809523809523808e-06, 'epoch': 9.52}
  warnings.warn('Was asked to gather along dimension 0, but all '                                       
{'eval_loss': 1.956074595451355, 'eval_accuracy': 0.6982444518052335, 'eval_runtime': 11.6326, 'eval_samples_per_second': 259.53, 'eval_steps_per_second': 4.126, 'epoch': 9.52}
100%|███████████████████████████████████████████████████████████████| 1890/1890 [24:27<00:00,  1.29it/s]
{'loss': 0.0414, 'grad_norm': 193851.890625, 'learning_rate': 2.1164021164021164e-06, 'epoch': 9.58}
{'loss': 0.0545, 'grad_norm': 902024.125, 'learning_rate': 1.8518518518518519e-06, 'epoch': 9.63}
{'loss': 0.05, 'grad_norm': 1045899.375, 'learning_rate': 1.5873015873015873e-06, 'epoch': 9.68}
{'loss': 0.0607, 'grad_norm': 68172.265625, 'learning_rate': 1.3227513227513228e-06, 'epoch': 9.74}
{'loss': 0.068, 'grad_norm': 561320.5625, 'learning_rate': 1.0582010582010582e-06, 'epoch': 9.79}
{'loss': 0.0318, 'grad_norm': 689333.6875, 'learning_rate': 7.936507936507937e-07, 'epoch': 9.84}
{'loss': 0.0163, 'grad_norm': 1180900.5, 'learning_rate': 5.291005291005291e-07, 'epoch': 9.89}
{'loss': 0.0302, 'grad_norm': 1057999.875, 'learning_rate': 2.6455026455026455e-07, 'epoch': 9.95}
{'loss': 0.054, 'grad_norm': 213777.078125, 'learning_rate': 0.0, 'epoch': 10.0}
{'train_runtime': 1469.3877, 'train_samples_per_second': 82.177, 'train_steps_per_second': 1.286, 'train_loss': 0.23850736479279855, 'epoch': 10.0}
Evaluation on English validation set:
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|███████████████████████████████████████████████████████████████████| 48/48 [00:11<00:00,  4.28it/s]
Accuracy on English validation set: 0.7121563431599868
Evaluation on Bengali dataset:
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
100%|███████████████████████████████████████████████████████████████████| 48/48 [00:10<00:00,  4.38it/s]
Accuracy on Bengali test data: 0.4773103676714144
