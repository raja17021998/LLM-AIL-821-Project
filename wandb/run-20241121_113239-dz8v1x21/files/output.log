  0%|                                                                             | 0/2 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
100%|█████████████████████████████████████████████████████████████████████| 2/2 [00:19<00:00,  9.84s/it]
{'train_runtime': 21.3926, 'train_samples_per_second': 0.935, 'train_steps_per_second': 0.093, 'train_loss': 1.1793701648712158, 'epoch': 2.0}
Evaluation on English validation set:
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 144.77it/s]
Accuracy on English validation set: 0.5
Evaluation on Bengali dataset:
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 288.88it/s]
Accuracy on Bengali test data: 0.5
