  0%|                                                                           | 0/126 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 79%|███████████████████████████████████████████████████▌             | 100/126 [03:45<00:55,  2.12s/it]/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
{'loss': 17.5918, 'grad_norm': 331.9644775390625, 'learning_rate': 3.3730158730158734e-05, 'epoch': 0.79}
{'loss': 2.0171, 'grad_norm': 182.81002807617188, 'learning_rate': 1.388888888888889e-05, 'epoch': 1.59}
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")     
{'eval_loss': 1.8359527587890625, 'eval_accuracy': 0.52, 'eval_runtime': 10.553, 'eval_samples_per_second': 18.952, 'eval_steps_per_second': 1.232, 'epoch': 1.59}
100%|█████████████████████████████████████████████████████████████████| 126/126 [04:40<00:00,  2.02s/it]2024-11-21 12:05:58,574 - WARNING - __main__ - Error while loading best model: 'method' object is not subscriptable
2024-11-21 12:05:58,576 - INFO - __main__ - Loaded best model and activated adapter: <bound method PeftAdapterMixin.active_adapters of BloomForSequenceClassification(
  (transformer): BloomModel(
    (word_embeddings): Embedding(250880, 2048)
    (word_embeddings_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
    (h): ModuleList(
      (0-23): 24 x BloomBlock(
        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
        (self_attention): BloomAttention(
          (query_key_value): Linear8bitLt(
            in_features=2048, out_features=6144, bias=True
            (lora_dropout): ModuleDict(
              (default): Dropout(p=0.1, inplace=False)
            )
            (lora_A): ModuleDict(
              (default): Linear(in_features=2048, out_features=8, bias=False)
            )
            (lora_B): ModuleDict(
              (default): Linear(in_features=8, out_features=6144, bias=False)
            )
            (lora_embedding_A): ParameterDict()
            (lora_embedding_B): ParameterDict()
          )
          (dense): Linear8bitLt(
            in_features=2048, out_features=2048, bias=True
            (lora_dropout): ModuleDict(
              (default): Dropout(p=0.1, inplace=False)
            )
            (lora_A): ModuleDict(
              (default): Linear(in_features=2048, out_features=8, bias=False)
            )
            (lora_B): ModuleDict(
              (default): Linear(in_features=8, out_features=2048, bias=False)
            )
            (lora_embedding_A): ParameterDict()
            (lora_embedding_B): ParameterDict()
          )
          (attention_dropout): Dropout(p=0.0, inplace=False)
        )
        (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
        (mlp): BloomMLP(
          (dense_h_to_4h): Linear8bitLt(in_features=2048, out_features=8192, bias=True)
          (gelu_impl): BloomGelu()
          (dense_4h_to_h): Linear8bitLt(in_features=8192, out_features=2048, bias=True)
        )
      )
    )
    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (score): ModulesToSaveWrapper(
    (original_module): Linear(in_features=2048, out_features=2, bias=False)
    (modules_to_save): ModuleDict(
      (default): Linear(in_features=2048, out_features=2, bias=False)
    )
  )
)>
100%|█████████████████████████████████████████████████████████████████| 126/126 [04:40<00:00,  2.23s/it]
{'train_runtime': 282.4668, 'train_samples_per_second': 7.08, 'train_steps_per_second': 0.446, 'train_loss': 8.148314763629248, 'epoch': 2.0}
Evaluation on English validation set:
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
100%|███████████████████████████████████████████████████████████████████| 13/13 [00:09<00:00,  1.35it/s]
Accuracy on English validation set: 0.535
Evaluation on Bengali dataset:
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
100%|███████████████████████████████████████████████████████████████████| 13/13 [00:07<00:00,  1.84it/s]
Accuracy on Bengali test data: 0.57
Traceback (most recent call last):
  File "/home/pooja/shashwat/LLM-Project/task3_lora.py", line 200, in <module>
    plt.savefig("plots/task3/task3_lora/training_validation_loss.png")  # Save the plot
  File "/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/matplotlib/pyplot.py", line 1228, in savefig
    res = fig.savefig(*args, **kwargs)  # type: ignore[func-returns-value]
  File "/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/matplotlib/figure.py", line 3395, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/matplotlib/backend_bases.py", line 2204, in print_figure
    result = print_method(
  File "/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/matplotlib/backend_bases.py", line 2054, in <lambda>
    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(
  File "/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py", line 496, in print_png
    self._print_pil(filename_or_obj, "png", pil_kwargs, metadata)
  File "/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py", line 445, in _print_pil
    mpl.image.imsave(
  File "/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/matplotlib/image.py", line 1676, in imsave
    image.save(fname, **pil_kwargs)
  File "/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/PIL/Image.py", line 2410, in save
    fp = builtins.open(filename, "w+b")
FileNotFoundError: [Errno 2] No such file or directory: 'plots/task3/task3_lora/training_validation_loss.png'
