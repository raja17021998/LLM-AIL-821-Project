  0%|                                                                            | 0/14 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
100%|███████████████████████████████████████████████████████████████████| 14/14 [00:32<00:00,  2.31s/it]
{'train_runtime': 33.9209, 'train_samples_per_second': 5.896, 'train_steps_per_second': 0.413, 'train_loss': 4.454450062343052, 'epoch': 2.0}
Evaluation on English validation set:
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 175.29it/s]
Accuracy on English validation set: 0.8
Evaluation on Bengali dataset:
/home/pooja/anaconda3/envs/kg_rag/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 307.03it/s]
Accuracy on Bengali test data: 0.6
